<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>FACER2VM | Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting</title><meta name=HandheldFriendly content=True><meta name=viewport content="width=device-width,minimum-scale=1,initial-scale=1"><link rel=stylesheet href=https://facer2vm.org/assets/css/style.c441c8f99776395c666cf386ed966f0c349094cc4975cf2bba661ecd079347ac.css integrity="sha256-xEHI&#43;Zd2OVxmbPOG7ZZvDDSQlMxJdc8rumYezQeTR6w="><script defer src=https://facer2vm.org/assets/js/script.9b2aec8de8e5cf51396182db4e1097aacc0247b7a44edf4fa6137430e95c5bbc.js integrity="sha256-myrsjejlz1E5YYLbThCXqswCR7ekTt9PphN0MOlcW7w="></script><link rel="shortcut icon" href=/favicon><link rel=icon type=image/png href=/favicon-192x192.png sizes=192x192><link rel=apple-touch-icon href=/favicon-180x180.png sizes=180x180><link rel=canonical href=https://facer2vm.org/posts/dynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting/><link rel=alternate type=application/ld+json href=https://facer2vm.org/posts/dynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting/index.jsonld title=FACER2VM><meta property=og:title content="Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting"><meta property=og:description content="We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection on unconstrained faces. Our DAC-CSR divides facial landmark detection into three cascaded sub-tasks: face bounding box refinement, general CSR and attention-controlled CSR."><meta property=og:type content=article><meta property=og:url content=https://facer2vm.org/posts/dynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting/><meta property=article:published_time content=2017-07-03T10:00:00&#43;00:00><meta property=article:modified_time content=2018-10-25T10:17:23&#43;01:00><meta name=twitter:card content=summary><meta name=twitter:title content="Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting"><meta name=twitter:description content="We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection on unconstrained faces. Our DAC-CSR divides facial landmark detection into three cascaded sub-tasks: face bounding box refinement, general CSR and attention-controlled CSR."><meta name=referrer content=no-referrer-when-downgrade><meta name=generator content="Hugo 0.49.2"><meta name=robots content="index, follow"></head><body class="posts page production"><div id=scroll><main><article class=rows><header id=header class="main-column posts page"><h1 class=headline>Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting</h1><div class=meta><span class=authors><a href=/people/zhenhua-feng/ rel=author>Zhenhua Feng</a></span>
<span class=divider>|</span>
<time class=date datetime=2017-07-03>3 Jul 2017</time></div></header><div id=squealer></div><div id=main class="main-column posts page"><div class=content><p>We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic
Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection on
unconstrained faces. Our DAC-CSR divides facial landmark detection into three
cascaded sub-tasks: face bounding box refinement, general CSR and
attention-controlled CSR. The first two stages refine initial face bounding
boxes and output intermediate facial landmarks. Then, an online dynamic model
selection method is used to choose appropriate domain-specific CSRs for further
landmark refinement.</p><p><em>The proposed DAC-CSR has three stages in cascade: face bounding box refinement,
general CSR and domain-specific CSR.</em><br><img src=/content/images/2017/10/acsr.png alt="The three stages of DAC-CSR"></p><p>The key innovation of our DAC-CSR is the fault-tolerant mechanism, using fuzzy
set sample weighting for attention-controlled domain-specific model training.
Moreover, we advocate data augmentation with a simple but effective 2D profile
face generator, and context-aware feature extraction for better facial feature
representation. Experimental results obtained on challenging datasets
demonstrate the merits of our DAC-CSR over the state-of-the-art.</p><h3 id=presentation>Presentation</h3><p><em>This paper was presented at <a href=http://cvpr2017.thecvf.com/>CVPR 2017</a>.</em></p><p><strong>When:</strong> 22-25 July 2017<br><strong>Where:</strong> Hawaii Convention Center<br>Honolulu, Hawaii</p><h3 id=attachments>Attachments</h3><ul><li><a href=https://ln.facer2vm.org/cvpr2017_dac-csr_pdf>Full-text</a> (3.52 Mb) &ndash; cite as:<br>Z-H Feng, J Kittler, W Christmas, P Huber, X-J Wu, Dynamic Attention-controlled
Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set
Sample Weighting, Proc. Conf. on Computer Vision and Pattern Recognition, 2017</li></ul></div><div class=info><div class=tags><a href=/tags/publications/ class="tags tags-publications button" rel=tag>Publications</a></div><aside class=social><a class=twitter href="https://twitter.com/share?text=Dynamic%20Attention-controlled%20Cascaded%20Shape%20Regression%20Exploiting%20Training%20Data%20Augmentation%20and%20Fuzzy-set%20Sample%20Weighting&url=https%3a%2f%2ffacer2vm.org%2fposts%2fdynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting%2f" target=_blank rel="noopener external nofollow noreferrer" referrerpolicy=no-referrer><i class="ic ic-twitter"></i><span class=hidden>Twitter</span></a>
<a class=facebook href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ffacer2vm.org%2fposts%2fdynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting%2f" target=_blank rel="noopener external nofollow noreferrer" referrerpolicy=no-referrer><i class="ic ic-facebook"></i><span class=hidden>Facebook</span></a>
<a class=googleplus href="https://plus.google.com/share?url=https%3a%2f%2ffacer2vm.org%2fposts%2fdynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting%2f" target=_blank rel="noopener external nofollow noreferrer" referrerpolicy=no-referrer><i class="ic ic-googleplus"></i><span class=hidden>Google+</span></a></aside></div><section class="people node columns summary"><figure class=profile-image><img src=/people/zhenhua-feng/profile_image.png alt="Zhenhua Feng"></figure><div class="rows bio"><header><h2 class=name><a href=/people/zhenhua-feng/>Dr Zhenhua Feng</a></h2></header><blockquote class=about cite=/people/zhenhua-feng/><p></blockquote><footer class=meta><ul><li class="location ic ic-location">Guildford, UK<li class="website ic ic-link"><a href=https://sites.google.com/view/fengzhenhua rel="noopener external">Website</a></ul></footer></div></section></div></article><nav id=links class="main-column posts page"><ul class=nav><li class=previous><a href=/posts/efficient-3d-morphable-face-model-fitting/ rel=prev><section class=teaser><i class="ic ic-arrow-left"></i><h2 class=headline>Efficient 3D Morphable Face Model Fitting</h2><p class=excerpt>3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach.</p></section></a><li class=next><a href=/posts/face-and-soft-biometrics-recognition-for-smart-cities-applications/ rel=next><section class=teaser><i class="ic ic-arrow-right"></i><h2 class=headline>Face and soft biometrics recognition for smart cities applications</h2><p class=excerpt>Prof Josef Kittler participated in the 3rd IEEE International Smart Cities Conference held at Jiangnan University, Wuxi, China on 14-17 September …</p></section></a></ul></nav></main><footer id=footer class=main-column><div class=credits><p class=copyright><a href=https://facer2vm.org/>© 2018 FACER2VM</a><p class=software>Published with <a href=//gohugo.io/>Hugo</a></div></footer><label class=hidden-close for=menu-switch></label></div><nav id=nav-buttons><a id=home-button class="nav-button button" href=https://facer2vm.org/><i class="ic ic-arrow-left"></i><span class=caption>Home</span></a>
<label id=menu-button class="nav-button button" for=menu-switch><i class="ic ic-menu"></i><span class=caption>Menu</span></label></nav><nav id=menu><p class=nav-label>Menu</p><ul><li class=nav- role=presentation><a href=/><span>Home</span></a><li class=nav-tags_publications role=presentation><a href=/tags/publications/><span>Publications</span></a><li class=nav-tags_invited-talks role=presentation><a href=/tags/invited-talks/><span>Invited talks</span></a><li class=nav-tags_in-the-news role=presentation><a href=/tags/in-the-news/><span>In the news</span></a><li class=nav-tags_software role=presentation><a href=/tags/software/><span>Software</span></a><li class=nav-about role=presentation><a href=/about/><span>About</span></a><li class=nav-management-structure role=presentation><a href=/management-structure/><span>Management structure</span></a><li class=nav-twitter><a href=//twitter.com/paul_koppen title=@Paul_Koppen><i class="ic ic-twitter"></i>Twitter</a><li class=nav-rss><a rel=alternate type=application/rss+xml href=https://facer2vm.org/index.xml><i class="ic ic-rss"></i>Subscribe</a></ul><label for=menu-switch class="close-button button">Close</label>
<input type=checkbox id=menu-switch value=open tabindex=-1 role=switch aria-checked=false></nav></body></html>