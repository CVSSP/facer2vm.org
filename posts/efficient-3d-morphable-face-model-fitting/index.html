<!doctype html><html lang=en itemscope itemtype=https://schema.org/BlogPosting><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>FACER2VM | Efficient 3D Morphable Face Model Fitting</title><meta name=description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta name=HandheldFriendly content=True><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://facer2vm.org/assets/css/style.f986643b474083333366fa6c66ba9f1af0685d40e484a01b5dbccbc6e4fbd41b.css integrity="sha256-&#43;YZkO0dAgzMzZvpsZrqfGvBoXUDkhKAbXbzLxuT71Bs="><link rel=canonical href=https://facer2vm.org/posts/efficient-3d-morphable-face-model-fitting/><meta property=og:title content="Efficient 3D Morphable Face Model Fitting"><meta property=og:description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta property=og:type content=article><meta property=og:url content=https://facer2vm.org/posts/efficient-3d-morphable-face-model-fitting/><meta property=article:published_time content=2017-02-22T15:17:00&#43;00:00><meta property=article:modified_time content=2017-02-22T15:17:00&#43;00:00><meta itemprop=name content="Efficient 3D Morphable Face Model Fitting"><meta itemprop=description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta itemprop=datePublished content=2017-02-22T15:17:00&#43;00:00><meta itemprop=dateModified content=2017-02-22T15:17:00&#43;00:00><meta itemprop=wordCount content=212><meta itemprop=keywords content=Publications,><meta name=twitter:card content=summary><meta name=twitter:title content="Efficient 3D Morphable Face Model Fitting"><meta name=twitter:description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta name=referrer content=no-referrer-when-downgrade><meta name=generator content="Hugo 0.49.2"><meta name=robots content="index, follow"></head><body class="posts page production"><div id=wrapper><header id=header class="posts page"><h1 class=title>Efficient 3D Morphable Face Model Fitting</h1><div class=meta><span class=authors><a href=/people/patrik-huber/ class="people people-patrik-huber">Patrik Huber</a></span>
<span class=divider>|</span>
<time class=date datetime=2017-02-22>22 Feb 2017</time></div></header><main id=main><div class=speed_up_rendering><article class="posts page main"><section class=content><p>3D face reconstruction of shape and skin texture from a single 2D image can be
performed using a 3D Morphable Model (3DMM) in an analysis-by-synthesis
approach. However, performing this reconstruction (fitting) efficiently and
accurately in a general imaging scenario is a challenge. Such a scenario would
involve a perspective camera to describe the geometric projection from 3D to 2D,
and the Phong model to characterise illumination. Under these imaging
assumptions the reconstruction problem is nonlinear and, consequently,
computationally very demanding. In this work, we present an efficient stepwise
3DMM-to-2D image-fitting procedure, which sequentially optimises the pose,
shape, light direction, light strength and skin texture parameters in separate
steps. By linearising each step of the fitting process we derive closed-form
solutions for the recovery of the respective parameters, leading to efficient
fitting. The proposed optimisation process involves all the pixels of the input
image, rather than randomly selected subsets, which enhances the accuracy of the
fitting. It is referred to as Efficient Stepwise Optimisation (ESO).</p><h3 id=details>Details</h3><p><em>This work was published in <a href=//www.journals.elsevier.com/pattern-recognition>Pattern Recognition</a>.</em></p><p><strong>Volume:</strong> 67<br><strong>Year:</strong> 2017<br><strong>Pages:</strong> 366-379<br><strong>DOI:</strong> <a href=//dx.doi.org/10.1016/j.patcog.2017.02.007>10.1016/j.patcog.2017.02.007</a></p><h3 id=attachments>Attachments</h3><ul><li><a href=//ln.facer2vm.org/pr2017-eso_pdf>Full-text PDF</a> (3.43 Mb) &ndash; cite as:<br>G Hu, F Yan, J Kittler, W Christmas, C Chan, Z Feng, P Huber, Efficient 3D
Morphable Face Model Fitting, Pattern Recognition, 67:366-367, 2017</li></ul></section><section class=info><div class=social><a class=twitter href="https://twitter.com/share?text=Efficient%203D%20Morphable%20Face%20Model%20Fitting&url=https%3a%2f%2ffacer2vm.org%2fposts%2fefficient-3d-morphable-face-model-fitting%2f" onclick="window.open(this.href,'twitter-share','width=550,height=235');return false;"><i class="ic ic-twitter"></i><span class=hidden>Twitter</span></a>
<a class=facebook href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ffacer2vm.org%2fposts%2fefficient-3d-morphable-face-model-fitting%2f" onclick="window.open(this.href,'facebook-share','width=580,height=296');return false;"><i class="ic ic-facebook"></i><span class=hidden>Facebook</span></a>
<a class=googleplus href="https://plus.google.com/share?url=https%3a%2f%2ffacer2vm.org%2fposts%2fefficient-3d-morphable-face-model-fitting%2f" onclick="window.open(this.href,'google-plus-share','width=490,height=530');return false;"><i class="ic ic-googleplus"></i><span class=hidden>Google+</span></a><div class=clear></div></div><aside class=tags><a href=/tags/publications/ class="tags tags-publications button">Publications</a></aside><div class=clear></div><article class="people node summary"><figure class=avatar><img src=/people/patrik-huber/profile_image.jpg alt="Patrik Huber"></figure><div class=bio><header><h2 class=name><a href=/people/patrik-huber/>Patrik Huber</a></h2></header><blockquote class=about cite=.RelPermalink><p></blockquote><footer class=meta><span class=location><i class="ic ic-location"></i>Guildford, UK</span>
<span class=website><i class="ic ic-link"></i><a href=//patrikhuber.ch/ rel="noopener external">Website</a></span></footer></div></article></section><nav class=nav><a class=next href=/posts/dynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting/><section class=teaser><i class="ic ic-arrow-left"></i><h2 class=title>Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting</h2><p class=excerpt>We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection …</p></section></a><a class=previous href=/posts/smile-youre-on-camera-and-it-knows-who-you-are/><section class=teaser><i class="ic ic-arrow-right"></i><h2 class=title>Smile, you&#39;re on camera, and it knows who you are</h2><p class=excerpt>Smile, you&rsquo;re on camera, and it knows who you are
BBC, 7 February 2017</p></section></a><div class=clear></div></nav></article></div></main><footer id=footer role=contentinfo><div class=line_over><section class=credits><span class=copyright><a href=https://facer2vm.org/>© 2018 FACER2VM</a></span>
<span class=theme>Theme <a href=//github.com/zutrinken/attila>Attila</a> by <a href=//zutrinken.com rel=nofollow>zutrinken</a></span>
<span class=software>Published with <a href=//gohugo.io/>Hugo</a></span></section></div></footer><label class=hidden-close for=menu-switch></label></div><nav id=nav-buttons><a id=home-button class="nav-button button" href=https://facer2vm.org/><i class="ic ic-arrow-left"></i>Home</a></span>
<label id=menu-button class="nav-button button" for=menu-switch><i class="ic ic-menu"></i>Menu</label></nav><nav id=menu><p class=nav-label>Menu</p><ul><li class=nav- role=presentation><a href=/><span>Home</span></a></li><li class=nav-tags_publications role=presentation><a href=/tags/publications/><span>Publications</span></a></li><li class=nav-tags_invited-talks role=presentation><a href=/tags/invited-talks/><span>Invited talks</span></a></li><li class=nav-tags_in-the-news role=presentation><a href=/tags/in-the-news/><span>In the news</span></a></li><li class=nav-tags_software role=presentation><a href=/tags/software/><span>Software</span></a></li><li class=nav-about role=presentation><a href=/about/><span>About</span></a></li><li class=nav-management-structure role=presentation><a href=/management-structure/><span>Management structure</span></a></li><li class=nav-rss><a rel=alternate type=application/rss+xml href=https://facer2vm.org/index.xml><i class="ic ic-rss"></i>Subscribe</a></li></ul><label for=menu-switch class="close-button button">Close</label>
<input type=checkbox id=menu-switch value=open tabindex=-1 role=switch aria-checked=false></nav><script src=https://facer2vm.org/assets/js/script.9ef495dbb7e34b70e47b500e9929bcc16ae636bf481e3d1ab5c17ce44856dcf3.js integrity="sha256-nvSV27fjS3Dke1AOmSm8wWrmNr9IHj0atcF85EhW3PM="></script></body></html>