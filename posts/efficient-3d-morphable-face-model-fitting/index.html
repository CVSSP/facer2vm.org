<!doctype html><html lang=en itemscope itemtype=https://schema.org/BlogPosting><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>FACER2VM | Efficient 3D Morphable Face Model Fitting</title><meta name=description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta name=HandheldFriendly content=True><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://facer2vm.org/assets/css/style.19b2f98ad683157dd9485b10e04a39d0633c226028959302c3182a413343ebe3.css integrity="sha256-GbL5itaDFX3ZSFsQ4Eo50GM8ImAolZMCwxgqQTND6&#43;M="><script defer src=https://facer2vm.org/assets/js/script.0f3b5c3b75b6bc353c85bd0b72e8af88d0d174656be4b3766d562ddf45f67b07.js integrity="sha256-DztcO3W2vDU8hb0LcuiviNDRdGVr5LN2bVYt30X2ewc="></script><link rel=canonical href=https://facer2vm.org/posts/efficient-3d-morphable-face-model-fitting/><meta property=og:title content="Efficient 3D Morphable Face Model Fitting"><meta property=og:description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta property=og:type content=article><meta property=og:url content=https://facer2vm.org/posts/efficient-3d-morphable-face-model-fitting/><meta property=article:published_time content=2017-02-22T15:17:00&#43;00:00><meta property=article:modified_time content=2017-02-22T15:17:00&#43;00:00><meta itemprop=name content="Efficient 3D Morphable Face Model Fitting"><meta itemprop=description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta itemprop=datePublished content=2017-02-22T15:17:00&#43;00:00><meta itemprop=dateModified content=2017-02-22T15:17:00&#43;00:00><meta itemprop=wordCount content=212><meta itemprop=keywords content=Publications,><meta name=twitter:card content=summary><meta name=twitter:title content="Efficient 3D Morphable Face Model Fitting"><meta name=twitter:description content="3D face reconstruction of shape and skin texture from a single 2D image using a 3D Morphable Model (3DMM) in an analysis-by-synthesis approach."><meta name=referrer content=no-referrer-when-downgrade><meta name=generator content="Hugo 0.49.2"><meta name=robots content="index, follow"></head><body class="posts page production"><div id=scroll><main><article class=rows><header id=header class="main-column posts page"><h1 class=headline>Efficient 3D Morphable Face Model Fitting</h1><div class=meta><span class=authors><a href=/people/patrik-huber/ class="people people-patrik-huber">Patrik Huber</a></span>
<span class=divider>|</span>
<time class=date datetime=2017-02-22>22 Feb 2017</time></div></header><div id=squealer></div><div id=main class="main-column posts page"><div class=content><p>3D face reconstruction of shape and skin texture from a single 2D image can be
performed using a 3D Morphable Model (3DMM) in an analysis-by-synthesis
approach. However, performing this reconstruction (fitting) efficiently and
accurately in a general imaging scenario is a challenge. Such a scenario would
involve a perspective camera to describe the geometric projection from 3D to 2D,
and the Phong model to characterise illumination. Under these imaging
assumptions the reconstruction problem is nonlinear and, consequently,
computationally very demanding. In this work, we present an efficient stepwise
3DMM-to-2D image-fitting procedure, which sequentially optimises the pose,
shape, light direction, light strength and skin texture parameters in separate
steps. By linearising each step of the fitting process we derive closed-form
solutions for the recovery of the respective parameters, leading to efficient
fitting. The proposed optimisation process involves all the pixels of the input
image, rather than randomly selected subsets, which enhances the accuracy of the
fitting. It is referred to as Efficient Stepwise Optimisation (ESO).</p><h3 id=details>Details</h3><p><em>This work was published in <a href=//www.journals.elsevier.com/pattern-recognition>Pattern Recognition</a>.</em></p><p><strong>Volume:</strong> 67<br><strong>Year:</strong> 2017<br><strong>Pages:</strong> 366-379<br><strong>DOI:</strong> <a href=//dx.doi.org/10.1016/j.patcog.2017.02.007>10.1016/j.patcog.2017.02.007</a></p><h3 id=attachments>Attachments</h3><ul><li><a href=//ln.facer2vm.org/pr2017-eso_pdf>Full-text PDF</a> (3.43 Mb) &ndash; cite as:<br>G Hu, F Yan, J Kittler, W Christmas, C Chan, Z Feng, P Huber, Efficient 3D
Morphable Face Model Fitting, Pattern Recognition, 67:366-367, 2017</li></ul></div><div class=info><div class=tags><a href=/tags/publications/ class="tags tags-publications button">Publications</a></div><aside class=social><a class=twitter href="https://twitter.com/share?text=Efficient%203D%20Morphable%20Face%20Model%20Fitting&url=https%3a%2f%2ffacer2vm.org%2fposts%2fefficient-3d-morphable-face-model-fitting%2f" target=_blank rel="noopener external nofollow noreferrer" referrerpolicy=no-referrer onclick="window.open(this.href,'twitter-share','width=550,height=235');return false;"><i class="ic ic-twitter"></i><span class=hidden>Twitter</span></a>
<a class=facebook href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ffacer2vm.org%2fposts%2fefficient-3d-morphable-face-model-fitting%2f" target=_blank rel="noopener external nofollow noreferrer" referrerpolicy=no-referrer onclick="window.open(this.href,'facebook-share','width=580,height=296');return false;"><i class="ic ic-facebook"></i><span class=hidden>Facebook</span></a>
<a class=googleplus href="https://plus.google.com/share?url=https%3a%2f%2ffacer2vm.org%2fposts%2fefficient-3d-morphable-face-model-fitting%2f" target=_blank rel="noopener external nofollow noreferrer" referrerpolicy=no-referrer onclick="window.open(this.href,'google-plus-share','width=490,height=530');return false;"><i class="ic ic-googleplus"></i><span class=hidden>Google+</span></a></aside></div><section class="people node columns summary"><figure class=profile-image><img src=/people/patrik-huber/profile_image.jpg alt="Patrik Huber"></figure><div class="rows bio"><header><h2 class=name>Patrik Huber</h2></header><div class=about><p></div><footer class=meta><span class=location><i class="ic ic-location"></i>Guildford, UK</span>
<span class=website><i class="ic ic-link"></i><a href=//patrikhuber.ch/ rel="noopener external">Website</a></span></footer></div></section></div></article><div id=links class="main-column posts page"><div class=nav><a class=previous href=/posts/dynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting/><section class=teaser><i class="ic ic-arrow-left"></i><h2 class=headline>Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting</h2><p class=excerpt>We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection …</p></section></a><a class=next href=/posts/smile-youre-on-camera-and-it-knows-who-you-are/><section class=teaser><i class="ic ic-arrow-right"></i><h2 class=headline>Smile, you&#39;re on camera, and it knows who you are</h2><p class=excerpt>Smile, you&rsquo;re on camera, and it knows who you are
BBC, 7 February 2017</p></section></a></div></div></main><footer id=footer class=main-column><div class=credits><p class=copyright><a href=https://facer2vm.org/>© 2018 FACER2VM</a><p class=software>Published with <a href=//gohugo.io/>Hugo</a></div></footer><label class=hidden-close for=menu-switch></label></div><nav id=nav-buttons><a id=home-button class="nav-button button" href=https://facer2vm.org/><i class="ic ic-arrow-left"></i><span class=caption>Home</span></a>
<label id=menu-button class="nav-button button" for=menu-switch><i class="ic ic-menu"></i><span class=caption>Menu</span></label></nav><nav id=menu><p class=nav-label>Menu</p><ul><li class=nav- role=presentation><a href=/><span>Home</span></a><li class=nav-tags_publications role=presentation><a href=/tags/publications/><span>Publications</span></a><li class=nav-tags_invited-talks role=presentation><a href=/tags/invited-talks/><span>Invited talks</span></a><li class=nav-tags_in-the-news role=presentation><a href=/tags/in-the-news/><span>In the news</span></a><li class=nav-tags_software role=presentation><a href=/tags/software/><span>Software</span></a><li class=nav-about role=presentation><a href=/about/><span>About</span></a><li class=nav-management-structure role=presentation><a href=/management-structure/><span>Management structure</span></a><li class=nav-twitter><a href=//twitter.com/paul_koppen title=@Paul_Koppen><i class="ic ic-twitter"></i>Twitter</a><li class=nav-rss><a rel=alternate type=application/rss+xml href=https://facer2vm.org/index.xml><i class="ic ic-rss"></i>Subscribe</a></ul><label for=menu-switch class="close-button button">Close</label>
<input type=checkbox id=menu-switch value=open tabindex=-1 role=switch aria-checked=false></nav></body></html>