<!doctype html><html lang=en itemscope itemtype=https://schema.org/BlogPosting><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>FACER2VM | Unconstrained face recognition: Approaches to face normalisation</title><meta name=description content="A two-day event to brainstorm on new ideas for face recognition. Model-based or model-free. Using deep neural nets or not."><meta name=HandheldFriendly content=True><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://facer2vm.org/assets/css/style.5b3462c2eef9dca7b91cd492dbc96930a5e136a52af3d973aad094d65a4c51ab.css integrity="sha256-WzRiwu753Ke5HNSS28lpMKXhNqUq89lzqtCU1lpMUas="><link rel=canonical href=https://facer2vm.org/posts/unconstrained-face-recognition-approaches-to-face-normalisation/><meta property=og:title content="Unconstrained face recognition: Approaches to face normalisation"><meta property=og:description content="A two-day event to brainstorm on new ideas for face recognition. Model-based or model-free. Using deep neural nets or not."><meta property=og:type content=article><meta property=og:url content=https://facer2vm.org/posts/unconstrained-face-recognition-approaches-to-face-normalisation/><meta property=article:published_time content=2016-09-15T14:13:00&#43;00:00><meta property=article:modified_time content=2016-09-15T14:13:00&#43;00:00><meta itemprop=name content="Unconstrained face recognition: Approaches to face normalisation"><meta itemprop=description content="A two-day event to brainstorm on new ideas for face recognition. Model-based or model-free. Using deep neural nets or not."><meta itemprop=datePublished content=2016-09-15T14:13:00&#43;00:00><meta itemprop=dateModified content=2016-09-15T14:13:00&#43;00:00><meta itemprop=wordCount content=160><meta itemprop=keywords content=Events,><meta name=twitter:card content=summary><meta name=twitter:title content="Unconstrained face recognition: Approaches to face normalisation"><meta name=twitter:description content="A two-day event to brainstorm on new ideas for face recognition. Model-based or model-free. Using deep neural nets or not."><meta name=referrer content=no-referrer-when-downgrade><meta name=generator content="Hugo 0.49.2"><meta name=robots content="index, follow"></head><body class="posts page production"><div id=wrapper><header id=header class="posts page"><h1 class=title>Unconstrained face recognition: Approaches to face normalisation</h1><div class=meta><span class=authors><a href=/people/chi-ho-chan/ class="people people-chi-ho-chan">Chi Ho Chan</a>, <a href=/people/zhenhua-feng/ class="people people-zhenhua-feng">Zhenhua Feng</a>, <a href=/people/patrik-huber/ class="people people-patrik-huber">Patrik Huber</a>, <a href=/people/tae-kyun-kim/ class="people people-tae-kyun-kim">Tae-Kyun Kim</a>, <a href=/people/josef-kittler/ class="people people-josef-kittler">Josef Kittler</a>, <a href=/people/muhammad-rana/ class="people people-muhammad-rana">Muhammad Rana</a>, <a href=/people/fei-yan/ class="people people-fei-yan">Fei Yan</a>, <a href=/people/stefanos-zafeiriou/ class="people people-stefanos-zafeiriou">Stefanos Zafeiriou</a></span>
<span class=divider>|</span>
<time class=date datetime=2016-09-15>15 Sep 2016</time></div></header><main id=main><div class=speed_up_rendering><article class="posts page main"><section class=content><p>This two-day brainstorming workshop explores the various approaches to
unconstrained face recognition. From model-based face normalisation methods to
end-to-end deep learning based methods. Also video-based approaches, such as 3D
face reconstruction and 3D model fitting, will be addressed.</p><p><a href=//goo.gl/8Mwc6o>Register your attendance</a> before Thursday 8 September, so we can
cater for lunch.</p><h2 id=speakers>Speakers</h2><ul><li>Dr Chi Ho Chan</li><li>Dr Zhenhua Feng</li><li>Mr Patrik Huber</li><li>Dr Tae-Kyun Kim</li><li>Prof Josef Kittler</li><li>Dr Shervin Rahimzadeh Arashloo</li><li>Dr Muhammad Rana</li><li>Dr William Smith</li><li>Dr Fei Yan</li><li>Dr Stefanos Zafeiriou</li></ul><h2 id=details>Details</h2><p><strong>When:</strong> Thursday 15 September from 10am to 5.30pm, and<br>Friday 16 September from 9.30am to 5:30pm (2016)<br><strong>Where:</strong> CVSSP Seminar Room (35 BA 00)<br>Centre for Vision, Speech and Signal Processing<br>University of Surrey<br>Guildford, GU2 7XH<br><strong>Registration:</strong> The event is organised for FACER2VM members. To keep track of
numbers and to cater for lunch, we kindly request to please <a href=//goo.gl/8Mwc6o>register your
attendance</a>.</p><ul><li><a href=//ln.facer2vm.org/facer2vm-ws-ufr_agenda>Programme</a> (pdf, 262 Kb)</li><li><a href=//ln.facer2vm.org/surrey-campus-map>University of Surrey Campus Map</a> (pdf, 2.53 Mb)</li></ul></section><section class=info><div class=social><a class=twitter href="https://twitter.com/share?text=Unconstrained%20face%20recognition%3a%20Approaches%20to%20face%20normalisation&url=https%3a%2f%2ffacer2vm.org%2fposts%2funconstrained-face-recognition-approaches-to-face-normalisation%2f" onclick="window.open(this.href,'twitter-share','width=550,height=235');return false;"><i class="ic ic-twitter"></i><span class=hidden>Twitter</span></a>
<a class=facebook href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ffacer2vm.org%2fposts%2funconstrained-face-recognition-approaches-to-face-normalisation%2f" onclick="window.open(this.href,'facebook-share','width=580,height=296');return false;"><i class="ic ic-facebook"></i><span class=hidden>Facebook</span></a>
<a class=googleplus href="https://plus.google.com/share?url=https%3a%2f%2ffacer2vm.org%2fposts%2funconstrained-face-recognition-approaches-to-face-normalisation%2f" onclick="window.open(this.href,'google-plus-share','width=490,height=530');return false;"><i class="ic ic-googleplus"></i><span class=hidden>Google+</span></a><div class=clear></div></div><aside class=tags><a href=/tags/events/ class="tags tags-events button">Events</a></aside><div class=clear></div><aside class=people><p class=note>This post was a collaboration between:</p><p class=names><a href=/people/chi-ho-chan/ class="people people-chi-ho-chan">Chi Ho Chan</a>, <a href=/people/zhenhua-feng/ class="people people-zhenhua-feng">Zhenhua Feng</a>, <a href=/people/patrik-huber/ class="people people-patrik-huber">Patrik Huber</a>, <a href=/people/tae-kyun-kim/ class="people people-tae-kyun-kim">Tae-Kyun Kim</a>, <a href=/people/josef-kittler/ class="people people-josef-kittler">Josef Kittler</a>, <a href=/people/muhammad-rana/ class="people people-muhammad-rana">Muhammad Rana</a>, <a href=/people/fei-yan/ class="people people-fei-yan">Fei Yan</a>, <a href=/people/stefanos-zafeiriou/ class="people people-stefanos-zafeiriou">Stefanos Zafeiriou</a></p></aside></section><nav class=nav><a class=next href=/posts/the-surrey-face-model/><section class=teaser><i class="ic ic-arrow-left"></i><h2 class=title>The Surrey Face Model</h2><p class=excerpt>This page is concerned with the availability and downloading of the 3D morphable face models created at the Centre of Vision, Speech and Signal …</p></section></a><a class=previous href=/posts/3d-morphable-face-model-and-its-applications-at-amdo-2016/><section class=teaser><i class="ic ic-arrow-right"></i><h2 class=title>3D Morphable Face Model and its Applications (at AMDO 2016)</h2><p class=excerpt>Invited paper at AMDO 2016 about the 3D Morphable Face Model and its applications.</p></section></a><div class=clear></div></nav></article></div></main><footer id=footer><div><section class=credits><span class=copyright><a href=https://facer2vm.org/>© 2018 FACER2VM</a></span>
<span class=software>Published with <a href=//gohugo.io/>Hugo</a></span></section></div></footer><label class=hidden-close for=menu-switch></label></div><nav id=nav-buttons><a id=home-button class="nav-button button" href=https://facer2vm.org/><i class="ic ic-arrow-left"></i>Home</a></span>
<label id=menu-button class="nav-button button" for=menu-switch><i class="ic ic-menu"></i>Menu</label></nav><nav id=menu><p class=nav-label>Menu</p><ul><li class=nav- role=presentation><a href=/><span>Home</span></a></li><li class=nav-tags_publications role=presentation><a href=/tags/publications/><span>Publications</span></a></li><li class=nav-tags_invited-talks role=presentation><a href=/tags/invited-talks/><span>Invited talks</span></a></li><li class=nav-tags_in-the-news role=presentation><a href=/tags/in-the-news/><span>In the news</span></a></li><li class=nav-tags_software role=presentation><a href=/tags/software/><span>Software</span></a></li><li class=nav-about role=presentation><a href=/about/><span>About</span></a></li><li class=nav-management-structure role=presentation><a href=/management-structure/><span>Management structure</span></a></li><li class=nav-rss><a rel=alternate type=application/rss+xml href=https://facer2vm.org/index.xml><i class="ic ic-rss"></i>Subscribe</a></li></ul><label for=menu-switch class="close-button button">Close</label>
<input type=checkbox id=menu-switch value=open tabindex=-1 role=switch aria-checked=false></nav><script src=https://facer2vm.org/assets/js/script.9ef495dbb7e34b70e47b500e9929bcc16ae636bf481e3d1ab5c17ce44856dcf3.js integrity="sha256-nvSV27fjS3Dke1AOmSm8wWrmNr9IHj0atcF85EhW3PM="></script></body></html>