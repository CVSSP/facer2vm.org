<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>FACER2VM</title><meta name=HandheldFriendly content=True><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://facer2vm.org/assets/css/style.f986643b474083333366fa6c66ba9f1af0685d40e484a01b5dbccbc6e4fbd41b.css integrity="sha256-&#43;YZkO0dAgzMzZvpsZrqfGvBoXUDkhKAbXbzLxuT71Bs="><link rel=canonical href=https://facer2vm.org/people/zhenhua-feng/><link rel=alternate href=https://facer2vm.org/people/zhenhua-feng/index.xml type=application/rss+xml title=FACER2VM><link rel=feed href=https://facer2vm.org/people/zhenhua-feng/index.xml type=application/rss+xml title=FACER2VM><meta property=og:title content><meta property=og:description content="Face Matching for Automatic Identity Retrieval, Recognition, Verification and Management"><meta property=og:type content=website><meta property=og:url content=https://facer2vm.org/people/zhenhua-feng/><meta property=og:updated_time content=2017-10-12T15:10:36&#43;00:00><meta itemprop=name content><meta itemprop=description content="Face Matching for Automatic Identity Retrieval, Recognition, Verification and Management"><meta name=twitter:card content=summary><meta name=twitter:title content><meta name=twitter:description content="Face Matching for Automatic Identity Retrieval, Recognition, Verification and Management"><meta name=referrer content=no-referrer-when-downgrade><meta name=generator content="Hugo 0.49.2"><meta name=robots content="index, follow"></head><body class="people node production"><div id=wrapper><header id=header class="people node"><h1 class=title></h1><div class=description></div></header><main id=main><div class=speed_up_rendering><article class="people node main"><section class=header><article class="people node summary"><figure class=avatar><img src=/people/zhenhua-feng/profile_image.png alt="Zhenhua Feng"></figure><div class=bio><header><h2 class=name>Dr Zhenhua Feng</h2></header><section class=about><p></section><footer class=meta><span class=stats><i class="ic ic-pencil"></i>4 posts</span>
<span class=location><i class="ic ic-location"></i>Guildford, UK</span></footer></div></article></section><section class=content></section></article><article class="posts page summary"><header><h2 class=title><a href=https://facer2vm.org/posts/fg2018/>IEEE FG 2018 Workshop on Dense 3D Reconstruction of 2D Face Images in the Wild</a></h2></header><section class=meta><a href=/people/zhenhua-feng/ class="people people-zhenhua-feng">Zhenhua Feng</a>
on <a href=/tags/events/ class="tags tags-events">Events</a>
<span class=divider>|</span>
<time datetime=2017-10-12>12 Oct 2017</time></section><blockquote class=excerpt cite=.RelPermalink><p>News 01-FEB-2018: The evaluation script of the competition is available via https://github.com/patrikhuber/fg2018-competition. You have to use the script and the provided 7 3D facial landmarks for evaluation. You also …</blockquote></article><article class="posts page summary"><header><h2 class=title><a href=https://facer2vm.org/posts/dynamic-attention-controlled-cascaded-shape-regression-exploiting-training-data-augmentation-and-fuzzy-set-sample-weighting/>Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting</a></h2></header><section class=meta><a href=/people/zhenhua-feng/ class="people people-zhenhua-feng">Zhenhua Feng</a>
on <a href=/tags/publications/ class="tags tags-publications">Publications</a>
<span class=divider>|</span>
<time datetime=2017-07-03>3 Jul 2017</time></section><blockquote class=excerpt cite=.RelPermalink><p>We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection on unconstrained faces. Our DAC-CSR divides facial landmark detection …</blockquote></article><article class="posts page summary"><header><h2 class=title><a href=https://facer2vm.org/posts/unconstrained-face-recognition-approaches-to-face-normalisation/>Unconstrained face recognition: Approaches to face normalisation</a></h2></header><section class=meta><a href=/people/chi-ho-chan/ class="people people-chi-ho-chan">Chi Ho Chan</a>, <a href=/people/zhenhua-feng/ class="people people-zhenhua-feng">Zhenhua Feng</a>, <a href=/people/patrik-huber/ class="people people-patrik-huber">Patrik Huber</a>, <a href=/people/tae-kyun-kim/ class="people people-tae-kyun-kim">Tae-Kyun Kim</a>, <a href=/people/josef-kittler/ class="people people-josef-kittler">Josef Kittler</a>, <a href=/people/muhammad-rana/ class="people people-muhammad-rana">Muhammad Rana</a>, <a href=/people/fei-yan/ class="people people-fei-yan">Fei Yan</a>, <a href=/people/stefanos-zafeiriou/ class="people people-stefanos-zafeiriou">Stefanos Zafeiriou</a>
on <a href=/tags/events/ class="tags tags-events">Events</a>
<span class=divider>|</span>
<time datetime=2016-09-15>15 Sep 2016</time></section><blockquote class=excerpt cite=.RelPermalink><p>A two-day event to brainstorm on new ideas for face recognition. Model-based or model-free. Using deep neural nets or not.</blockquote></article><article class="posts page summary"><header><h2 class=title><a href=https://facer2vm.org/posts/advancements-in-face-research/>Advancements in Face Research: A Conversation Between Humans and Machines</a></h2></header><section class=meta><a href=/people/patrik-huber/ class="people people-patrik-huber">Patrik Huber</a>, <a href=/people/paul-koppen/ class="people people-paul-koppen">Paul Koppen</a>, <a href=/people/zhenhua-feng/ class="people people-zhenhua-feng">Zhenhua Feng</a>
on <a href=/tags/events/ class="tags tags-events">Events</a>
<span class=divider>|</span>
<time datetime=2016-06-23>23 Jun 2016</time></section><blockquote class=excerpt cite=.RelPermalink><p>Announcement for the Advancements in Face Research event.</blockquote></article><nav class=pagination role=pagination><div class=left></div><div class=info>Page 1 of 1</div><div class=right></div></nav></div></main><footer id=footer role=contentinfo><div class=line_over><section class=credits><span class=copyright><a href=https://facer2vm.org/>© 2018 FACER2VM</a></span>
<span class=theme>Theme <a href=//github.com/zutrinken/attila>Attila</a> by <a href=//zutrinken.com rel=nofollow>zutrinken</a></span>
<span class=software>Published with <a href=//gohugo.io/>Hugo</a></span></section></div></footer><label class=hidden-close for=menu-switch></label></div><nav id=nav-buttons><a id=home-button class="nav-button button" href=https://facer2vm.org/><i class="ic ic-arrow-left"></i>Home</a></span>
<label id=menu-button class="nav-button button" for=menu-switch><i class="ic ic-menu"></i>Menu</label></nav><nav id=menu><p class=nav-label>Menu</p><ul><li class=nav- role=presentation><a href=/><span>Home</span></a></li><li class=nav-tags_publications role=presentation><a href=/tags/publications/><span>Publications</span></a></li><li class=nav-tags_invited-talks role=presentation><a href=/tags/invited-talks/><span>Invited talks</span></a></li><li class=nav-tags_in-the-news role=presentation><a href=/tags/in-the-news/><span>In the news</span></a></li><li class=nav-tags_software role=presentation><a href=/tags/software/><span>Software</span></a></li><li class=nav-about role=presentation><a href=/about/><span>About</span></a></li><li class=nav-management-structure role=presentation><a href=/management-structure/><span>Management structure</span></a></li><li class=nav-rss><a href=https://facer2vm.org/index.xml><i class="ic ic-rss"></i>Subscribe</a></li></ul><label for=menu-switch class="close-button button">Close</label>
<input type=checkbox id=menu-switch value=open tabindex=-1 role=switch></nav><script type=text/javascript src=https://facer2vm.org/assets/js/script.9ef495dbb7e34b70e47b500e9929bcc16ae636bf481e3d1ab5c17ce44856dcf3.js integrity="sha256-nvSV27fjS3Dke1AOmSm8wWrmNr9IHj0atcF85EhW3PM="></script></body></html>